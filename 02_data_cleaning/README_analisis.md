# An√°lisis Exploratorio de Datos (EDA)

Este documento resume los resultados del an√°lisis exploratorio realizado sobre los datasets **MELD** (entrenamiento) y **Twitter** (testing) para clasificaci√≥n de emociones y sentimientos.

## üìä Archivos Generados

El script `exploratory_analysis.py` genera los siguientes archivos:

1. **distribucion_emociones.png** - Gr√°ficos de barras comparando la distribuci√≥n de emociones
2. **distribucion_sentimientos.png** - Gr√°ficos de barras comparando la distribuci√≥n de sentimientos
3. **propiedades_textuales.png** - Histogramas, box plots y violin plots de longitudes de texto
4. **analisis_vocabulario.png** - Visualizaciones del solapamiento de vocabulario
5. **twitter_unique_words.txt** - Lista de 507 palabras √∫nicas en Twitter pero ausentes en MELD

## üéØ An√°lisis Implementados

### 1. An√°lisis de Distribuci√≥n de Clases

**Objetivo:** Comparar la frecuencia de cada categor√≠a en ambos datasets para determinar sesgo y necesidad de m√©tricas como F1-ponderado.

**Resultados Clave:**

#### Emociones (MELD)
- **Neutral**: 4,710 (47.15%) - Clase dominante
- Joy: 1,743 (17.45%)
- Anger: 1,109 (11.10%)
- Surprise: 1,205 (12.06%)
- Sadness: 683 (6.84%)
- Fear: 268 (2.68%)
- Disgust: 271 (2.71%)

#### Emociones (Twitter)
- **Neutral**: 94 (59.87%) - Clase a√∫n m√°s dominante
- Joy: 16 (10.19%)
- Anger: 15 (9.55%)
- Fear: 11 (7.01%)
- Surprise: 10 (6.37%)
- Disgust: 8 (5.10%)
- Sadness: 3 (1.91%)

**Conclusiones:**
- Ambos datasets presentan **desbalance de clases** significativo
- La clase "Neutral" domina en ambos datasets (>47%)
- **Recomendaci√≥n:** Utilizar **F1-ponderado** como m√©trica principal debido al desbalance
- Twitter tiene un desbalance m√°s severo (59.87% neutral vs 47.15% en MELD)

---

### 2. An√°lisis de Propiedades Textuales

**Objetivo:** Analizar longitudes de di√°logos (n√∫mero de tokens) para determinar padding adecuado y complejidad del dominio.

**Estad√≠sticas Descriptivas:**

| M√©trica | MELD | Twitter |
|---------|------|---------|
| **Media** | ~10 tokens | ~20 tokens |
| **Desviaci√≥n est√°ndar** | Variable | Variable |
| **M√≠nimo** | Variable | Variable |
| **Cuartil 75%** | Variable | Variable |
| **M√°ximo** | Variable | Variable |

**Recomendaciones para CNN:**
- **Padding recomendado:** Basado en el cuartil 75% de ambos datasets
- El padding debe cubrir aproximadamente el 75% de los textos
- Twitter tiende a tener textos m√°s largos que MELD

**Implicaciones:**
- La diferencia en longitudes puede afectar la efectividad del padding en CNN
- La dispersi√≥n influir√° en la matriz TF-IDF
- Los textos m√°s cortos de MELD pueden requerir ajustes en la arquitectura CNN

---

### 3. An√°lisis L√©xico y de Vocabulario

**Objetivo:** Evaluar el solapamiento de vocabularios entre dominios, crucial para el √©xito de Naive Bayes y CNN.

**Tama√±o de Corpus:**

| Dataset | Total Tokens | Vocabulario √önico |
|---------|--------------|-------------------|
| **MELD** | ~90,000+ | ~8,000+ palabras |
| **Twitter** | 3,140 | 1,062 palabras |

**Solapamiento de Vocabulario:**
- **Palabras en com√∫n:** Variable
- **Palabras solo en MELD:** Variable
- **Palabras solo en Twitter:** **507 palabras** (guardadas en `twitter_unique_words.txt`)

**Porcentaje de Cobertura:**
- Porcentaje de vocabulario de Twitter presente en MELD: **[Calculado en ejecuci√≥n]**

**Palabras M√°s Frecuentes (Top 5):**

MELD:
1. "i" - 4,469 ocurrencias
2. [Otras palabras comunes]

Twitter:
1. [Palabras espec√≠ficas del dominio de servicio al cliente]
2. Nombres de marcas (@amazonhelp, @delta, @uber_support, etc.)
3. T√©rminos t√©cnicos (app, email, chat, etc.)

**Palabras √önicas en Twitter:**
El archivo `twitter_unique_words.txt` contiene 507 palabras que incluyen:
- **Menciones de marcas:** @amazonhelp, @delta, @uber_support, @tmobilehelp
- **T√©rminos de servicio al cliente:** feedback, dm, customerservice, billing
- **Vocabulario t√©cnico:** app, email, flight, mobile, network
- **Jerga de Twitter:** lol, thx, ppl, rly
- **URLs:** M√∫ltiples enlaces https://t.co/...
- **Emojis:** üòÇ, üò≠, ü§î, etc.
- **Texto en otros idiomas:** Japon√©s („Åä„Åã„Åë„Åô„Çã, „Åî„Åñ„ÅÑ„Åæ„Åõ„Çì, etc.)

**Implicaciones:**

üî¥ **Si cobertura < 50%:**
- ‚ö†Ô∏è **ADVERTENCIA CR√çTICA:** Baja cobertura de vocabulario
- Naive Bayes tendr√° dificultades significativas con palabras no vistas
- CNN puede no identificar patrones relevantes en Twitter
- **Recomendaci√≥n:** Considerar t√©cnicas de aumentaci√≥n de datos o transfer learning

üü° **Si cobertura 50-75%:**
- ‚ö†Ô∏è **ATENCI√ìN:** Cobertura moderada
- Se esperan limitaciones en la generalizaci√≥n
- **Recomendaci√≥n:** Implementar t√©cnicas de regularizaci√≥n y validaci√≥n cruzada

üü¢ **Si cobertura > 75%:**
- ‚úì Buena cobertura de vocabulario
- Los modelos deber√≠an generalizar adecuadamente

---

## üöÄ C√≥mo Ejecutar el An√°lisis

```bash
# Desde el directorio ra√≠z del proyecto
python 02_data_cleaning/exploratory_analysis.py
```

**Requisitos:**
- pandas
- numpy
- matplotlib
- seaborn
- spacy (con modelo en_core_web_sm)
- contractions

**Instalaci√≥n de dependencias:**
```bash
pip install pandas numpy matplotlib seaborn spacy contractions
python -m spacy download en_core_web_sm
```

---

## üìù Conclusiones Generales

### Para Naive Bayes (TF-IDF):
- El desbalance de clases requerir√° m√©tricas como F1-ponderado
- La presencia de 507 palabras √∫nicas en Twitter (no en MELD) limitar√° el rendimiento
- El modelo depender√° fuertemente de las palabras en com√∫n entre datasets

### Para CNN (GloVe):
- El padding deber√° ajustarse seg√∫n las diferencias de longitud
- Las diferencias en vocabulario pueden afectar la capa de embedding
- La arquitectura debe ser robusta a textos de diferentes longitudes
- El uso de embeddings pre-entrenados (GloVe) puede mitigar el problema de vocabulario

### Recomendaciones Metodol√≥gicas:
1. **Utilizar F1-ponderado** como m√©trica principal de evaluaci√≥n
2. **Implementar validaci√≥n cruzada** para evaluar robustez
3. **Considerar t√©cnicas de balanceo** (SMOTE, class weights)
4. **Analizar matriz de confusi√≥n** para identificar clases problem√°ticas
5. **Evaluar transfer learning** si la cobertura de vocabulario es baja

---

## üìä Visualizaciones

Todas las visualizaciones se encuentran en el directorio `02_data_cleaning/`:

- `distribucion_emociones.png` - Comparaci√≥n lado a lado de distribuciones
- `distribucion_sentimientos.png` - An√°lisis de balance de sentimientos
- `propiedades_textuales.png` - 4 gr√°ficos: histogramas, box plots y violin plots
- `analisis_vocabulario.png` - 4 visualizaciones de an√°lisis l√©xico

---

## üîç Pr√≥ximos Pasos

1. Aplicar vectorizadores (TF-IDF y GloVe)
2. Entrenar modelos (Naive Bayes y CNN)
3. Evaluar rendimiento con m√©tricas apropiadas
4. Analizar resultados y ajustar hiperpar√°metros
5. Documentar hallazgos finales

---

**Autor:** An√°lisis automatizado generado por `exploratory_analysis.py`  
**Fecha:** 2024  
**Proyecto:** Clasificaci√≥n de Emociones y Sentimientos - MELD vs Twitter
